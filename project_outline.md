저상버스 혼잡도 예측 서비스
│
├─ Phase 1: 데이터 기반 마련 (1~2주)
│  ├─ 1-1: 노선 기본 정보 파악
│  ├─ 1-2: API 및 데이터 소스 검증
│  ├─ 1-3: 과거 데이터 수집 (3개월)
│  └─ 1-4: 실시간 데이터 수집 시작
│
├─ Phase 2: 데이터 정제 및 분석 (1주)
│  ├─ 2-1: 결측치/이상치 처리
│  ├─ 2-2: 혼잡도 지표 정의 및 계산
│  ├─ 2-3: EDA (탐색적 데이터 분석)
│  └─ 2-4: 피처 엔지니어링
│
├─ Phase 3: 머신러닝 모델 개발 (2주)
│  ├─ 3-1: XGBoost 모델 구축
│  ├─ 3-2: 모델 하이퍼파라미터 튜닝
│  ├─ 3-3: 모델 성능 평가
│  └─ 3-4: 모델 저장 및 버전 관리

## 1. 문제 정의, 프로젝트의 목표와 의의

- **`목표`**: **공공 데이터를 활용해 실시간 저상버스 위치를 파악하고, 과거 혼잡도 데이터를 기반으로 특정 정류장에서의 '탑승 가능 확률'을 예측하여 제공함. → 확률 예측 자체에 포커스**
---

## 2. 필요한 데이터

- 공공데이터포털(API): 서울시/경기도 버스 실시간 도착 정보 API (저상버스 여부 필드 활용).
- 서울시 열린데이터광장: 버스 노선별/정류소별/시간대별 승하차 인원 통계 및 혼잡도 데이터.
- 기상청 API: 날씨(강수 여부 등)에 따른 대중교통 이용객 변화 반영을 위한 기상 데이터.

* 더 좋은 데이터셋이 있다면 변경 가능 

---

## 3. 구현에 필요한 모델 및 흐름도

1. API를 통해 실시간 버스 위치와 과거 승하차 패턴 데이터를 수집
2. 시간대(출퇴근 등), 요일, 날씨, 정류장 위치(환승역 여부) 등을 변수로 생성
3. XGBoost 또는 LightGBM 회귀 모델을 사용하여 현재 버스가 해당 정류장에 도착했을 때의 예상 혼잡도를 0~1 사이의 확률값으로 도출
4. 저상버스일 경우 그 버스의  탑승 가능 확률(Continuous)을 결합하여 사용자에게 시각화

<Phase 1: 데이터 기반 마련 (1~2주)>
목표
606번, 420번 버스의 과거 3개월 데이터와 실시간 데이터 수집 파이프라인 구축

상세 단계
1-1: 노선 기본 정보 파악
작업: 606번, 420번 버스의 정류장 수, 운영 시간, 배차 간격 등 파악
산출물: 노선 정보 JSON 파일
소요 시간: 2~3일
담당 도구: 웹 검색, 공공데이터포털
1-2: API 및 데이터 소스 검증
작업:
서울시 버스 API (실시간 도착 정보) 접근 가능성 확인
공공데이터포털에서 제공하는 데이터 형식 확인
기상청 API 키 발급
산출물: API 문서, 샘플 데이터 수집 스크립트
소요 시간: 3~4일
담당 도구: Python requests, API 테스트 도구
1-3: 과거 데이터 수집 (3개월)
작업:
서울시 열린데이터광장에서 606, 420번 버스의 지난 3개월(2025년 11월~2026년 1월) 승하차 데이터 다운로드
날씨 데이터 수집
공휴일/특수 이벤트 데이터 수집
산출물: CSV 파일 (606_data.csv, 420_data.csv, weather_data.csv)
소요 시간: 3~5일
담당 도구: pandas, 웹 크롤링, API
1-4: 실시간 데이터 수집 시작
작업:
실시간 버스 위치 API를 이용한 데이터 수집 스케줄러 설정
매일 새로운 데이터를 데이터베이스에 저장하는 파이프라인 구축
산출물: 데이터 수집 스크립트, 데이터베이스 스키마
소요 시간: 3~4일
담당 도구: APScheduler, PostgreSQL/SQLite, 백그라운드 작업 스케줄러

<Phase 2: 데이터 정제 및 분석 (1주)>
목표
수집된 데이터를 정제하고, 모델 학습을 위한 피처를 생성

상세 단계
2-1: 결측치/이상치 처리
작업:
결측치 비율 분석
결측치 채우기 (선형 보간, 시간대별 평균 등)
이상치 탐지 (IQR 방법, Z-score 등)
이상치 제거 또는 보정
산출물: 정제된 데이터 파일
소요 시간: 2~3일
담당 도구: pandas, numpy, matplotlib
2-2: 혼잡도 지표 정의 및 계산
작업:
혼잡도 정의: 각 정류장의 탑승객을 해당 정류장의 최대값으로 정규화 (0~1)
혼잡도 계산 및 검증
혼잡도 분포 확인
산출물: 혼잡도 지표가 추가된 데이터
소요 시간: 1~2일
담당 도구: pandas, numpy
2-3: EDA (탐색적 데이터 분석)
작업:
시간대별 혼잡도 패턴 분석 (출퇴근 시간 vs 한가한 시간)
요일별 혼잡도 패턴 (평일 vs 주말)
계절별 패턴 (겨울 vs 여름)
기상과 혼잡도의 관계
정류장별 혼잡도 분포
산출물: 시각화 자료 (그래프, 히트맵), 인사이트 보고서
소요 시간: 2~3일
담당 도구: matplotlib, seaborn, plotly
2-4: 피처 엔지니어링
작업:
시간 피처: 시간(0~23), 요일(0~6), 월(1~12)
시간대 피처: 아침 러시아워(7~9시), 저녁 러시아워(18~20시)
날짜 피처: 주말 여부, 공휴일 여부, 계절
외부 데이터 피처: 강수, 기온, 풍속
정류장 피처: 정류장 순번 (첫 역일수록 덜 혼잡)
시계열 피처: 지난 1시간, 1일, 1주일의 평균 혼잡도
산출물: 최종 학습 데이터 (모든 피처 포함)
소요 시간: 2~3일
담당 도구: pandas, numpy, sklearn

Phase 3: 머신러닝 모델 개발 (2주)
목표
혼잡도 예측 모델 개발 및 성능 최적화

<상세 단계>
3-1: XGBoost 모델 구축
작업:
606번, 420번 각각에 대해 별도의 XGBoost 모델 구축
훈련 데이터와 테스트 데이터 분할 (시계열 고려: 70% 훈련, 30% 테스트)
기본 XGBoost 모델 훈련
산출물: 초기 XGBoost 모델 (pkl 파일)
소요 시간: 2~3일
담당 도구: XGBoost, sklearn
3-2: 모델 하이퍼파라미터 튜닝
작업:
그리드 서치 또는 랜덤 서치를 이용한 최적 파라미터 탐색
주요 파라미터: n_estimators, max_depth, learning_rate, subsample, colsample_bytree
교차 검증 (Cross-validation)을 통한 성능 평가
산출물: 최적화된 XGBoost 모델
소요 시간: 3~4일
담당 도구: XGBoost, sklearn GridSearchCV
3-3: 모델 성능 평가
작업:
평가 지표 계산: MAE, RMSE, R²
시간대별 오류 분석 (출퇴근 시간 vs 한가한 시간에서의 정확도 차이)
요일별 오류 분석
혼잡도 구간별 오류 분석 (낮은 혼잡도 vs 높은 혼잡도)
모델 해석: 피처 중요도 분석
산출물: 성능 평가 리포트, 시각화 자료
소요 시간: 2~3일
담당 도구: sklearn metrics, matplotlib, SHAP
3-4: 모델 저장 및 버전 관리
작업:
최종 모델 저장 (pkl 파일)
모델 메타데이터 저장 (훈련 날짜, 버전, 성능 지표)
모델 버전 관리 (v1.0, v1.1 등)
모델 카드 작성 (모델 설명서)
산출물: 모델 파일 + 메타데이터
소요 시간: 1~2일
담당 도구: pickle, JSON